{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKzA88taPcrc",
        "outputId": "11bbfab9-fbc5-4201-dc68-18f7d3168a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample transactions: [['Robotic Arm', 'Food Packets'], ['Sleeping Bag', 'Treadmill', 'Food Packets'], ['Robotic Arm', 'Space Suit', '3D Printer'], ['Food Packets', 'Carbon Dioxide Scrubbers'], ['Sleeping Bag', 'Space Suit']]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from itertools import combinations  # Added missing import\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load raw lines manually (skip header)\n",
        "try:\n",
        "    with open(\"/content/drive/MyDrive/DataWarehouseDataMining/space.txt\", \"r\") as f:\n",
        "        lines = f.readlines()[1:]  # skip header line\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'sports.txt' not found. Please check the file path.\")\n",
        "    raise\n",
        "\n",
        "# Parse each line manually\n",
        "transactions_list = []\n",
        "for line in lines:\n",
        "    parts = line.strip().split(\",\")\n",
        "    items = [item.strip() for item in parts[1:] if item.strip()]  # skip TransactionID, ignore empty items\n",
        "    if items:  # only add non-empty transactions\n",
        "        transactions_list.append(items)\n",
        "\n",
        "# Check a few parsed transactions\n",
        "print(\"Sample transactions:\", transactions_list[:5])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_support(item, transactions):\n",
        "    count = sum(1 for transaction in transactions if set(item).issubset(set(transaction)))\n",
        "    return count / len(transactions) if transactions else 0\n",
        "\n",
        "def apriori(transactions, min_support):\n",
        "    itemsets = []\n",
        "    single_items = set(item for transaction in transactions for item in transaction)\n",
        "\n",
        "    # Step 1: Get frequent 1-itemsets\n",
        "    L1 = []\n",
        "    for item in single_items:\n",
        "        support = get_support([item], transactions)\n",
        "        if support >= min_support:\n",
        "            L1.append(([item], support))\n",
        "    itemsets.extend(L1)\n",
        "    if not L1:\n",
        "        return itemsets\n",
        "\n",
        "    # Step 2: Generate k-itemsets\n",
        "    k = 2\n",
        "    prev_frequent = [[item for item in items] for items, _ in L1]\n",
        "\n",
        "    while prev_frequent:\n",
        "        # Generate candidates by joining (k-1)-itemsets\n",
        "        candidates = []\n",
        "        for i in range(len(prev_frequent)):\n",
        "            for j in range(i + 1, len(prev_frequent)):\n",
        "                itemset1, itemset2 = prev_frequent[i], prev_frequent[j]\n",
        "                # Ensure itemsets differ by one item\n",
        "                if itemset1[:k-2] == itemset2[:k-2]:  # share first k-2 items\n",
        "                    candidate = sorted(list(set(itemset1 + itemset2)))\n",
        "                    if len(candidate) == k:\n",
        "                        # Check if all (k-1)-subsets are frequent\n",
        "                        subsets = [sorted(list(c)) for c in combinations(candidate, k-1)]\n",
        "                        if all(sorted(s) in prev_frequent for s in subsets):\n",
        "                            candidates.append(candidate)\n",
        "\n",
        "        # Remove duplicates\n",
        "        candidates = [list(c) for c in set(tuple(c) for c in candidates)]\n",
        "        if not candidates:\n",
        "            break\n",
        "\n",
        "        # Check support for candidates\n",
        "        Lk = []\n",
        "        for candidate in candidates:\n",
        "            support = get_support(candidate, transactions)\n",
        "            if support >= min_support:\n",
        "                Lk.append((candidate, support))\n",
        "\n",
        "        if not Lk:\n",
        "            break\n",
        "        itemsets.extend(Lk)\n",
        "        prev_frequent = [[item for item in items] for items, _ in Lk]\n",
        "        k += 1\n",
        "\n",
        "    return itemsets\n",
        "\n"
      ],
      "metadata": {
        "id": "MrL-jWatPfEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_confidence_lift(frequent_itemsets, transactions):\n",
        "    print(\"\\n Association Rules:\")\n",
        "    rules_found = False\n",
        "    for itemset, support in frequent_itemsets:\n",
        "        if len(itemset) >= 2:\n",
        "            for i in range(1, len(itemset)):\n",
        "                for antecedent in combinations(itemset, i):\n",
        "                    antecedent = list(antecedent)\n",
        "                    consequent = sorted(list(set(itemset) - set(antecedent)))\n",
        "                    antecedent_support = get_support(antecedent, transactions)\n",
        "                    consequent_support = get_support(consequent, transactions)\n",
        "                    if antecedent_support > 0 and consequent_support > 0:\n",
        "                        confidence = support / antecedent_support\n",
        "                        lift = confidence / consequent_support\n",
        "                        print(f\"{antecedent} => {consequent} | support={support:.2f}, confidence={confidence:.2f}, lift={lift:.2f}\")\n",
        "                        rules_found = True\n",
        "    if not rules_found:\n",
        "        print(\"No association rules found. Try lowering min_support or check dataset.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZB4CrDgQeeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Apriori algorithm\n",
        "min_support = 0.1\n",
        "frequent_itemsets = apriori(transactions_list, min_support)\n",
        "\n",
        "# Print frequent itemsets\n",
        "print(\"\\nðŸ“Œ Frequent Itemsets (Support >= 0.2):\")\n",
        "for itemset, support in frequent_itemsets:\n",
        "    print(f\"{itemset} - support: {support:.2f}\")\n",
        "\n",
        "# Calculate and print association rules\n",
        "calc_confidence_lift(frequent_itemsets, transactions_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqHft6aaQhA0",
        "outputId": "a01ecd73-9588-4317-bedc-552fe42404d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Œ Frequent Itemsets (Support >= 0.2):\n",
            "['Space Suit'] - support: 0.32\n",
            "['Robotic Arm'] - support: 0.34\n",
            "['Carbon Dioxide Scrubbers'] - support: 0.24\n",
            "['Treadmill'] - support: 0.28\n",
            "['Food Packets'] - support: 0.40\n",
            "['3D Printer'] - support: 0.28\n",
            "['Sleeping Bag'] - support: 0.32\n",
            "['Robotic Arm', 'Space Suit'] - support: 0.10\n",
            "['3D Printer', 'Sleeping Bag'] - support: 0.10\n",
            "['Food Packets', 'Sleeping Bag'] - support: 0.10\n",
            "['Robotic Arm', 'Sleeping Bag'] - support: 0.10\n",
            "['Food Packets', 'Treadmill'] - support: 0.12\n",
            "['Food Packets', 'Space Suit'] - support: 0.10\n",
            "['Food Packets', 'Robotic Arm'] - support: 0.14\n",
            "\n",
            " Association Rules:\n",
            "['Robotic Arm'] => ['Space Suit'] | support=0.10, confidence=0.29, lift=0.92\n",
            "['Space Suit'] => ['Robotic Arm'] | support=0.10, confidence=0.31, lift=0.92\n",
            "['3D Printer'] => ['Sleeping Bag'] | support=0.10, confidence=0.36, lift=1.12\n",
            "['Sleeping Bag'] => ['3D Printer'] | support=0.10, confidence=0.31, lift=1.12\n",
            "['Food Packets'] => ['Sleeping Bag'] | support=0.10, confidence=0.25, lift=0.78\n",
            "['Sleeping Bag'] => ['Food Packets'] | support=0.10, confidence=0.31, lift=0.78\n",
            "['Robotic Arm'] => ['Sleeping Bag'] | support=0.10, confidence=0.29, lift=0.92\n",
            "['Sleeping Bag'] => ['Robotic Arm'] | support=0.10, confidence=0.31, lift=0.92\n",
            "['Food Packets'] => ['Treadmill'] | support=0.12, confidence=0.30, lift=1.07\n",
            "['Treadmill'] => ['Food Packets'] | support=0.12, confidence=0.43, lift=1.07\n",
            "['Food Packets'] => ['Space Suit'] | support=0.10, confidence=0.25, lift=0.78\n",
            "['Space Suit'] => ['Food Packets'] | support=0.10, confidence=0.31, lift=0.78\n",
            "['Food Packets'] => ['Robotic Arm'] | support=0.14, confidence=0.35, lift=1.03\n",
            "['Robotic Arm'] => ['Food Packets'] | support=0.14, confidence=0.41, lift=1.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **QUE 2**"
      ],
      "metadata": {
        "id": "aqGY4j-gQy4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Simplified FP-Growth algorithm\n",
        "def fpgrowth(transactions, min_support):\n",
        "    # Step 1: Count item frequencies\n",
        "    item_counts = defaultdict(int)\n",
        "    for transaction in transactions:\n",
        "        for item in transaction:\n",
        "            item_counts[item] += 1\n",
        "\n",
        "    # Step 2: Filter frequent items and sort by frequency\n",
        "    total = len(transactions)\n",
        "    frequent_items = [(item, count/total) for item, count in item_counts.items() if count/total >= min_support]\n",
        "    frequent_items.sort(key=lambda x: (-x[1], x[0]))  # Sort by support (descending), then item\n",
        "    frequent_itemset = {item for item, _ in frequent_items}\n",
        "\n",
        "    # Step 3: Create ordered transactions\n",
        "    ordered_transactions = []\n",
        "    for transaction in transactions:\n",
        "        ordered = [item for item in transaction if item in frequent_itemset]\n",
        "        ordered.sort(key=lambda x: (-item_counts[x], x))  # Sort by frequency\n",
        "        if ordered:\n",
        "            ordered_transactions.append(ordered)\n",
        "\n",
        "    # Step 4: Generate frequent patterns (simulating conditional pattern base)\n",
        "    patterns = []\n",
        "    for item, support in frequent_items:\n",
        "        # Find transactions containing this item\n",
        "        conditional_transactions = [\n",
        "            [i for i in t if item_counts[i] >= item_counts[item] and i != item]\n",
        "            for t in ordered_transactions if item in t\n",
        "        ]\n",
        "        # Generate patterns for this conditional base\n",
        "        for k in range(1, max(len(t) for t in conditional_transactions) + 1):\n",
        "            candidate_counts = defaultdict(int)\n",
        "            for t in conditional_transactions:\n",
        "                for combo in combinations(t, k):\n",
        "                    candidate_counts[combo] += 1\n",
        "\n",
        "            for combo, count in candidate_counts.items():\n",
        "                # Add the current item to the pattern\n",
        "                pattern = sorted(list(combo) + [item])\n",
        "                support = count / total\n",
        "                if support >= min_support:\n",
        "                    patterns.append((pattern, support))\n",
        "\n",
        "    # Include 1-itemsets\n",
        "    patterns.extend([([item], support) for item, support in frequent_items])\n",
        "\n",
        "    # Remove duplicates\n",
        "    unique_patterns = {}\n",
        "    for pattern, support in patterns:\n",
        "        key = tuple(sorted(pattern))\n",
        "        if key not in unique_patterns or unique_patterns[key] < support:\n",
        "            unique_patterns[key] = support\n",
        "\n",
        "    return [(list(k), v) for k, v in unique_patterns.items()]\n",
        "\n",
        "# Association rules calculation (reused)\n",
        "def calc_confidence_lift(frequent_itemsets, transactions):\n",
        "    print(\"\\n Association Rules:\")\n",
        "    rules_found = False\n",
        "    for itemset, support in frequent_itemsets:\n",
        "        if len(itemset) >= 2:\n",
        "            for i in range(1, len(itemset)):\n",
        "                for antecedent in combinations(itemset, i):\n",
        "                    antecedent = list(antecedent)\n",
        "                    consequent = sorted(list(set(itemset) - set(antecedent)))\n",
        "                    antecedent_support = get_support(antecedent, transactions)\n",
        "                    consequent_support = get_support(consequent, transactions)\n",
        "                    if antecedent_support > 0 and consequent_support > 0:\n",
        "                        confidence = support / antecedent_support\n",
        "                        lift = confidence / consequent_support\n",
        "                        print(f\"{antecedent} => {consequent} | support={support:.2f}, confidence={confidence:.2f}, lift={lift:.2f}\")\n",
        "                        rules_found = True\n",
        "    if not rules_found:\n",
        "        print(\"No association rules found. Try lowering min_support or check dataset.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "M4PQFMU3ache"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== FP-Growth Results ===\")\n",
        "frequent_patterns = fpgrowth(transactions_list, min_support)\n",
        "print(\" Frequent Itemsets from FP-Growth:\")\n",
        "for itemset, support in frequent_patterns:\n",
        "    print(f\"{itemset} - support: {support:.2f}\")\n",
        "calc_confidence_lift(frequent_patterns, transactions_list)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx501s02akvl",
        "outputId": "5ace6bf9-f793-4672-acd7-9f39816ae31e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== FP-Growth Results ===\n",
            " Frequent Itemsets from FP-Growth:\n",
            "['Food Packets', 'Robotic Arm'] - support: 0.14\n",
            "['Food Packets', 'Sleeping Bag'] - support: 0.10\n",
            "['Robotic Arm', 'Sleeping Bag'] - support: 0.10\n",
            "['Robotic Arm', 'Space Suit'] - support: 0.10\n",
            "['Food Packets', 'Space Suit'] - support: 0.10\n",
            "['3D Printer', 'Sleeping Bag'] - support: 0.10\n",
            "['Food Packets', 'Treadmill'] - support: 0.12\n",
            "['Food Packets'] - support: 0.40\n",
            "['Robotic Arm'] - support: 0.34\n",
            "['Sleeping Bag'] - support: 0.32\n",
            "['Space Suit'] - support: 0.32\n",
            "['3D Printer'] - support: 0.28\n",
            "['Treadmill'] - support: 0.28\n",
            "['Carbon Dioxide Scrubbers'] - support: 0.24\n",
            "\n",
            " Association Rules:\n",
            "['Food Packets'] => ['Robotic Arm'] | support=0.14, confidence=0.35, lift=1.03\n",
            "['Robotic Arm'] => ['Food Packets'] | support=0.14, confidence=0.41, lift=1.03\n",
            "['Food Packets'] => ['Sleeping Bag'] | support=0.10, confidence=0.25, lift=0.78\n",
            "['Sleeping Bag'] => ['Food Packets'] | support=0.10, confidence=0.31, lift=0.78\n",
            "['Robotic Arm'] => ['Sleeping Bag'] | support=0.10, confidence=0.29, lift=0.92\n",
            "['Sleeping Bag'] => ['Robotic Arm'] | support=0.10, confidence=0.31, lift=0.92\n",
            "['Robotic Arm'] => ['Space Suit'] | support=0.10, confidence=0.29, lift=0.92\n",
            "['Space Suit'] => ['Robotic Arm'] | support=0.10, confidence=0.31, lift=0.92\n",
            "['Food Packets'] => ['Space Suit'] | support=0.10, confidence=0.25, lift=0.78\n",
            "['Space Suit'] => ['Food Packets'] | support=0.10, confidence=0.31, lift=0.78\n",
            "['3D Printer'] => ['Sleeping Bag'] | support=0.10, confidence=0.36, lift=1.12\n",
            "['Sleeping Bag'] => ['3D Printer'] | support=0.10, confidence=0.31, lift=1.12\n",
            "['Food Packets'] => ['Treadmill'] | support=0.12, confidence=0.30, lift=1.07\n",
            "['Treadmill'] => ['Food Packets'] | support=0.12, confidence=0.43, lift=1.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare results\n",
        "print(f\"\\n Apriori found {len(frequent_itemsets)} itemsets\")\n",
        "print(f\" FP-Growth found {len(frequent_patterns)} itemsets\")\n",
        "print(\" In real-world, FP-Growth is faster because it avoids re-scanning data by building a tree. Apriori does many passes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1FNxX8darF2",
        "outputId": "2ec9819d-ab83-43b2-c307-22fa8157fdbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Apriori found 14 itemsets\n",
            " FP-Growth found 14 itemsets\n",
            " In real-world, FP-Growth is faster because it avoids re-scanning data by building a tree. Apriori does many passes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing using prebuilt algorithm"
      ],
      "metadata": {
        "id": "aXmh2KF-eMt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing using the pre build algorithm\n",
        "\n",
        "!pip install mlxtend"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9spsqC9ddDiY",
        "outputId": "65a3904a-b901-43c4-fc82-4581dde2f6ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.11/dist-packages (0.23.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.15.3)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.5.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# # Simulated dataset (replace with file loading in Colab)\n",
        "# sample_data = [\n",
        "#     [\"cricket bat\", \"cricket ball\", \"gloves\"],\n",
        "#     [\"football\", \"water bottle\", \"juice\"],\n",
        "#     [\"cricket bat\", \"cricket ball\", \"ice cream\"],\n",
        "#     [\"football\", \"juice\"],\n",
        "#     [\"cricket bat\", \"gloves\", \"water bottle\"],\n",
        "#     [\"football\", \"ice cream\", \"juice\"],\n",
        "#     [\"cricket ball\", \"gloves\"],\n",
        "#     [\"cricket bat\", \"football\", \"juice\"]\n",
        "# ]\n",
        "# transactions_list = sample_data\n",
        "\n",
        "# Uncomment to load from file in Colab\n",
        "\n",
        "try:\n",
        "    with open(\"/content/drive/MyDrive/DataWarehouseDataMining/space.txt\", \"r\") as f:\n",
        "        lines = f.readlines()[1:]  # skip header line\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'space.txt' not found. Please check the file path.\")\n",
        "    raise\n",
        "\n",
        "transactions_list = []\n",
        "for line in lines:\n",
        "    parts = line.strip().split(\",\")\n",
        "    items = [item.strip() for item in parts[1:] if item.strip()]\n",
        "    if items:\n",
        "        transactions_list.append(items)\n",
        "\n",
        "# Check a few parsed transactions\n",
        "print(\"Sample transactions:\", transactions_list[:5])\n",
        "\n",
        "# Prepare one-hot encoded DataFrame for mlxtend\n",
        "def prepare_data(transactions):\n",
        "    unique_items = sorted(set(item for transaction in transactions for item in transaction))\n",
        "    data = []\n",
        "    for transaction in transactions:\n",
        "        row = [1 if item in transaction else 0 for item in unique_items]\n",
        "        data.append(row)\n",
        "    return pd.DataFrame(data, columns=unique_items)\n",
        "\n",
        "df = prepare_data(transactions_list)\n",
        "\n",
        "# Run mlxtend Apriori\n",
        "min_support = 0.01\n",
        "print(\"\\n=== mlxtend Apriori Results ===\")\n",
        "frequent_itemsets_apriori = apriori(df, min_support=min_support, use_colnames=True)\n",
        "print(\"Frequent Itemsets:\")\n",
        "print(frequent_itemsets_apriori)\n",
        "rules_apriori = association_rules(frequent_itemsets_apriori, metric=\"confidence\", min_threshold=0.5)\n",
        "print(\"\\n Association Rules:\")\n",
        "if not rules_apriori.empty:\n",
        "    print(rules_apriori[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
        "else:\n",
        "    print(\"No association rules found.\")\n",
        "\n",
        "# Run mlxtend FP-Growth\n",
        "print(\"\\n=== mlxtend FP-Growth Results ===\")\n",
        "frequent_itemsets_fpgrowth = fpgrowth(df, min_support=min_support, use_colnames=True)\n",
        "print(\"Frequent Itemsets:\")\n",
        "print(frequent_itemsets_fpgrowth)\n",
        "rules_fpgrowth = association_rules(frequent_itemsets_fpgrowth, metric=\"confidence\", min_threshold=0.5)\n",
        "print(\"\\nAssociation Rules:\")\n",
        "if not rules_fpgrowth.empty:\n",
        "    print(rules_fpgrowth[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
        "else:\n",
        "    print(\"No association rules found.\")\n",
        "\n",
        "# Compare results\n",
        "print(f\"\\n mlxtend Apriori found {len(frequent_itemsets_apriori)} itemsets\")\n",
        "print(f\" mlxtend FP-Growth found {len(frequent_itemsets_fpgrowth)} itemsets\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFpII5UydcBd",
        "outputId": "196e04e4-f58f-4600-818a-5f39b8757417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample transactions: [['Robotic Arm', 'Food Packets'], ['Sleeping Bag', 'Treadmill', 'Food Packets'], ['Robotic Arm', 'Space Suit', '3D Printer'], ['Food Packets', 'Carbon Dioxide Scrubbers'], ['Sleeping Bag', 'Space Suit']]\n",
            "\n",
            "=== mlxtend Apriori Results ===\n",
            "Frequent Itemsets:\n",
            "    support                                           itemsets\n",
            "0      0.28                                       (3D Printer)\n",
            "1      0.24                         (Carbon Dioxide Scrubbers)\n",
            "2      0.40                                     (Food Packets)\n",
            "3      0.34                                      (Robotic Arm)\n",
            "4      0.32                                     (Sleeping Bag)\n",
            "5      0.32                                       (Space Suit)\n",
            "6      0.28                                        (Treadmill)\n",
            "7      0.08             (3D Printer, Carbon Dioxide Scrubbers)\n",
            "8      0.04                         (3D Printer, Food Packets)\n",
            "9      0.08                          (3D Printer, Robotic Arm)\n",
            "10     0.10                         (3D Printer, Sleeping Bag)\n",
            "11     0.06                           (3D Printer, Space Suit)\n",
            "12     0.02           (Food Packets, Carbon Dioxide Scrubbers)\n",
            "13     0.02            (Robotic Arm, Carbon Dioxide Scrubbers)\n",
            "14     0.06           (Sleeping Bag, Carbon Dioxide Scrubbers)\n",
            "15     0.02             (Space Suit, Carbon Dioxide Scrubbers)\n",
            "16     0.06              (Treadmill, Carbon Dioxide Scrubbers)\n",
            "17     0.14                        (Food Packets, Robotic Arm)\n",
            "18     0.10                       (Food Packets, Sleeping Bag)\n",
            "19     0.10                         (Space Suit, Food Packets)\n",
            "20     0.12                          (Treadmill, Food Packets)\n",
            "21     0.10                        (Robotic Arm, Sleeping Bag)\n",
            "22     0.10                          (Space Suit, Robotic Arm)\n",
            "23     0.04                           (Treadmill, Robotic Arm)\n",
            "24     0.04                         (Space Suit, Sleeping Bag)\n",
            "25     0.04                          (Treadmill, Sleeping Bag)\n",
            "26     0.06                            (Treadmill, Space Suit)\n",
            "27     0.02  (3D Printer, Sleeping Bag, Carbon Dioxide Scru...\n",
            "28     0.02            (3D Printer, Food Packets, Robotic Arm)\n",
            "29     0.02            (3D Printer, Robotic Arm, Sleeping Bag)\n",
            "30     0.02              (3D Printer, Space Suit, Robotic Arm)\n",
            "31     0.04          (Food Packets, Robotic Arm, Sleeping Bag)\n",
            "32     0.04            (Space Suit, Food Packets, Robotic Arm)\n",
            "33     0.04            (Treadmill, Food Packets, Sleeping Bag)\n",
            "\n",
            " Association Rules:\n",
            "                  antecedents     consequents  support  confidence      lift\n",
            "0  (3D Printer, Food Packets)   (Robotic Arm)     0.02         0.5  1.470588\n",
            "1   (Treadmill, Sleeping Bag)  (Food Packets)     0.04         1.0  2.500000\n",
            "\n",
            "=== mlxtend FP-Growth Results ===\n",
            "Frequent Itemsets:\n",
            "    support                                           itemsets\n",
            "0      0.40                                     (Food Packets)\n",
            "1      0.34                                      (Robotic Arm)\n",
            "2      0.32                                     (Sleeping Bag)\n",
            "3      0.28                                        (Treadmill)\n",
            "4      0.32                                       (Space Suit)\n",
            "5      0.28                                       (3D Printer)\n",
            "6      0.24                         (Carbon Dioxide Scrubbers)\n",
            "7      0.14                        (Food Packets, Robotic Arm)\n",
            "8      0.10                       (Food Packets, Sleeping Bag)\n",
            "9      0.04                         (Space Suit, Sleeping Bag)\n",
            "10     0.10                        (Robotic Arm, Sleeping Bag)\n",
            "11     0.04          (Food Packets, Robotic Arm, Sleeping Bag)\n",
            "12     0.12                          (Treadmill, Food Packets)\n",
            "13     0.04                          (Treadmill, Sleeping Bag)\n",
            "14     0.04                           (Treadmill, Robotic Arm)\n",
            "15     0.06                            (Treadmill, Space Suit)\n",
            "16     0.04            (Treadmill, Food Packets, Sleeping Bag)\n",
            "17     0.10                          (Space Suit, Robotic Arm)\n",
            "18     0.10                         (Space Suit, Food Packets)\n",
            "19     0.04            (Space Suit, Food Packets, Robotic Arm)\n",
            "20     0.08                          (3D Printer, Robotic Arm)\n",
            "21     0.06                           (3D Printer, Space Suit)\n",
            "22     0.10                         (3D Printer, Sleeping Bag)\n",
            "23     0.04                         (3D Printer, Food Packets)\n",
            "24     0.02            (3D Printer, Robotic Arm, Sleeping Bag)\n",
            "25     0.02              (3D Printer, Space Suit, Robotic Arm)\n",
            "26     0.02            (3D Printer, Food Packets, Robotic Arm)\n",
            "27     0.02           (Food Packets, Carbon Dioxide Scrubbers)\n",
            "28     0.08             (3D Printer, Carbon Dioxide Scrubbers)\n",
            "29     0.02            (Robotic Arm, Carbon Dioxide Scrubbers)\n",
            "30     0.06              (Treadmill, Carbon Dioxide Scrubbers)\n",
            "31     0.06           (Sleeping Bag, Carbon Dioxide Scrubbers)\n",
            "32     0.02             (Space Suit, Carbon Dioxide Scrubbers)\n",
            "33     0.02  (3D Printer, Sleeping Bag, Carbon Dioxide Scru...\n",
            "\n",
            "Association Rules:\n",
            "                  antecedents     consequents  support  confidence      lift\n",
            "0   (Treadmill, Sleeping Bag)  (Food Packets)     0.04         1.0  2.500000\n",
            "1  (3D Printer, Food Packets)   (Robotic Arm)     0.02         0.5  1.470588\n",
            "\n",
            " mlxtend Apriori found 34 itemsets\n",
            " mlxtend FP-Growth found 34 itemsets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "npqEfl26d3bz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}